{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10251,"status":"ok","timestamp":1716249790489,"user":{"displayName":"model_training","userId":"15059446775298759120"},"user_tz":360},"id":"G_6c-QcawMl4","outputId":"296e0ea8-ada0-4929-9c22-67736fa236d6"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.1 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install -q python-crfsuite"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11718,"status":"ok","timestamp":1716237960551,"user":{"displayName":"model_training","userId":"15059446775298759120"},"user_tz":360},"id":"-qYChaA4vju-","outputId":"f59d0581-fb81-4526-fcbf-97bd1e392bdf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":213,"status":"ok","timestamp":1716249709794,"user":{"displayName":"model_training","userId":"15059446775298759120"},"user_tz":360},"id":"erSTwP1jv-Cm"},"outputs":[],"source":["train=\"/content/drive/MyDrive/JCRSextoSemestre/GeneracionEtiquetado/train.txt\"\n","test=\"/content/drive/MyDrive/JCRSextoSemestre/GeneracionEtiquetado/test.txt\""]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":253,"status":"ok","timestamp":1716250996142,"user":{"displayName":"model_training","userId":"15059446775298759120"},"user_tz":360},"id":"MycKAJKbcvUH","outputId":"9f10ced5-f61f-4ba7-bac3-116950ca42cd"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     NCFS000       0.74      0.88      0.80        57\n","     NCMP000       1.00      0.25      0.40         4\n","     NCMS000       1.00      0.22      0.36         9\n","      NP0000       1.00      1.00      1.00        16\n","     NP00000       1.00      0.88      0.94        25\n","    PP3MS000       0.00      0.00      0.00         1\n","         RFC       1.00      1.00      1.00        16\n","       SPS00       0.92      0.97      0.94        96\n","     VMIP3P0       0.00      0.00      0.00         1\n","     VMIP3S0       0.83      0.90      0.86        21\n","     VMIS3P0       0.94      0.91      0.92        53\n","     VMIS3S0       0.83      0.80      0.82        25\n","\n","    accuracy                           0.89       324\n","   macro avg       0.77      0.65      0.67       324\n","weighted avg       0.89      0.89      0.88       324\n","\n","[[50  0  0  0  0  0  0  3  0  1  0  3]\n"," [ 0  1  0  0  0  0  0  1  0  1  1  0]\n"," [ 6  0  2  0  0  0  0  1  0  0  0  0]\n"," [ 0  0  0 16  0  0  0  0  0  0  0  0]\n"," [ 2  0  0  0 22  0  0  0  0  1  0  0]\n"," [ 0  0  0  0  0  0  0  1  0  0  0  0]\n"," [ 0  0  0  0  0  0 16  0  0  0  0  0]\n"," [ 2  0  0  0  0  0  0 93  0  1  0  0]\n"," [ 1  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 1  0  0  0  0  0  0  1  0 19  0  0]\n"," [ 3  0  0  0  0  0  0  1  0  0 48  1]\n"," [ 3  0  0  0  0  0  0  0  0  0  2 20]]\n"]}],"source":["import pycrfsuite\n","from sklearn.metrics import classification_report, confusion_matrix\n","\n","# Feature to read tagged sentences from a text file\n","def read_tagged_sentences(file_path):\n","    \"\"\"\n","    Reads sentences with tags from a specified file.\n","\n","    Args:\n","        file_path (str): The path to the file containing tagged sentences.\n","\n","    Returns:\n","        list: A list of sentences, where each sentence is a list of (word, tag) tuples.\n","    \"\"\"\n","    sentences = []\n","    with open(file_path, 'r', encoding='utf-8') as file:\n","        sentence = []\n","        for line in file:\n","            line = line.strip()\n","            if line:\n","                word, tag = line.split('#')\n","                sentence.append((word, tag))\n","            else:\n","                if sentence:\n","                    sentences.append(sentence)\n","                    sentence = []\n","        if sentence:\n","            sentences.append(sentence)\n","    return sentences\n","\n","# Read the tagged sentences from the training and test files\n","train_corpus = train\n","test_corpus = test\n","\n","train_tagged_sentences = read_tagged_sentences(train_corpus)\n","test_tagged_sentences = read_tagged_sentences(test_corpus)\n","\n","# Prepare training and test data\n","train_sentences = []\n","train_tag_sequences = []\n","\n","test_sentences = []\n","test_tag_sequences = []\n","\n","for sen in train_tagged_sentences:\n","    words, tags = zip(*sen)\n","    train_sentences.append(words)\n","    train_tag_sequences.append(tags)\n","\n","for sen in test_tagged_sentences:\n","    words, tags = zip(*sen)\n","    test_sentences.append(words)\n","    test_tag_sequences.append(tags)\n","\n","# Function to extract features from a word\n","def word2features(sent, i):\n","    \"\"\"\n","    Extracts features from a word in a sentence for use in a machine learning model.\n","\n","    Args:\n","        sent (list): The sentence containing the word, represented as a list of words.\n","        i (int): The index of the word in the sentence.\n","\n","    Returns:\n","        dict: A dictionary of features for the word.\n","    \"\"\"\n","    word = sent[i]\n","    features = {\n","        'bias': 1.0,\n","        'word.lower()': word.lower(),\n","        'word[-3:]': word[-3:],\n","        'word[-2:]': word[-2:],\n","        'word.isupper()': word.isupper(),\n","        'word.istitle()': word.istitle(),\n","        'word.isdigit()': word.isdigit(),\n","    }\n","    if i > 0:\n","        word1 = sent[i-1]\n","        features.update({\n","            '-1:word.lower()': word1.lower(),\n","            '-1:word.istitle()': word1.istitle(),\n","            '-1:word.isupper()': word1.isupper(),\n","        })\n","    else:\n","        features['BOS'] = True  # Señalamos el inicio de la oración\n","\n","    if i < len(sent)-1:\n","        word1 = sent[i+1]\n","        features.update({\n","            '+1:word.lower()': word1.lower(),\n","            '+1:word.istitle()': word1.istitle(),\n","            '+1:word.isupper()': word1.isupper(),\n","        })\n","    else:\n","        features['EOS'] = True  # Señalamos el final de la oración\n","\n","    return features\n","\n","# We convert a sentence into a list of characteristics\n","def sent2features(sent):\n","    \"\"\"\n","    Converts a sentence into a list of feature dictionaries for each word.\n","\n","    Args:\n","        sent (list): The sentence to convert, represented as a list of words.\n","\n","    Returns:\n","        list: A list of feature dictionaries, one for each word in the sentence.\n","    \"\"\"\n","    return [word2features(sent, i) for i in range(len(sent))]\n","\n","# Prepare training and test data for CRF\n","X_train = [sent2features(s) for s in train_sentences]\n","y_train = train_tag_sequences\n","\n","X_test = [sent2features(s) for s in test_sentences]\n","y_test = test_tag_sequences\n","\n","# Train the CRF model\n","trainer = pycrfsuite.Trainer(verbose=False)\n","for xseq, yseq in zip(X_train, y_train):\n","    trainer.append(xseq, yseq)\n","\n","trainer.set_params({\n","    'c1': 1.0,# Coefficient for L1 regularization\n","    'c2': 1.0,# Coefficient for L2 regularization\n","    'max_iterations': 50,# Maximum number of iterations\n","    'feature.possible_transitions': True\n","})\n","trainer.train('treebank_crf_model.crfsuite')\n","\n","# Evaluate the CRF model\n","tagger = pycrfsuite.Tagger()\n","tagger.open('treebank_crf_model.crfsuite')\n","\n","# Make predictions on the test set\n","y_pred = [tagger.tag(xseq) for xseq in X_test]\n","\n","# Flatten tag lists for evaluation\n","y_test_flat = [label for seq in y_test for label in seq]\n","y_pred_flat = [label for seq in y_pred for label in seq]\n","\n","# Print the ranking report\n","print(classification_report(y_test_flat, y_pred_flat, zero_division=0))\n","\n","# Print the confusion matrix\n","print(confusion_matrix(y_test_flat, y_pred_flat,))\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyM9p9SY6tj8lTptC2nP8r7x","mount_file_id":"1joWpw7_Y-JPdoeXnz1rZX88E7NdFpuyR","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
